
> options(prompt = "R> ", continue = "+  ", width = 80)

> pd <- packageDescription("mboost")

> if (any(is.na(pd))) {
+     install.packages("mboost", repos = "http://cran.at.r-project.org")
+     pd <- packageDescription("mboost")
+ }

> if (compareVersion(pd$Version, "2.1-0") < 0) {
+     warning("Current version of mboost is installed!")
+     install.packages("mboost", repos = "ht ..." ... [TRUNCATED]

> require("mboost")
Loading required package: mboost

> set.seed(190781)

> if (!file.exists("graphics")) dir.create("graphics")

> library("mboost")

> data("bodyfat")

> lm1 <- lm(DEXfat ~ hipcirc + kneebreadth + anthro3a,
+     data = bodyfat)

> coef(lm1)
(Intercept)     hipcirc kneebreadth    anthro3a
-75.2347840   0.5115264   1.9019904   8.9096375

> glm1 <- glmboost(DEXfat ~ hipcirc + kneebreadth +
+     anthro3a, data = bodyfat)

> coef(glm1, off2int = TRUE)
(Intercept)     hipcirc kneebreadth    anthro3a
-75.2073365   0.5114861   1.9005386   8.9071301

> preds <- names(bodyfat[, names(bodyfat) != "DEXfat"])

> fm <- as.formula(paste("DEXfat ~", paste(preds, collapse = "+")))

> fm
DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth +
    anthro3a + anthro3b + anthro3c + anthro4

> glm2a <- glmboost(fm, data = bodyfat)

> glm2b <- glmboost(DEXfat ~ ., data = bodyfat)

> identical(coef(glm2a), coef(glm2b))
[1] TRUE

> coef(glm2b, which = "")
 (Intercept)          age    waistcirc      hipcirc elbowbreadth  kneebreadth
 -98.8166077    0.0136017    0.1897156    0.3516258   -0.3841399    1.7365888
    anthro3a     anthro3b     anthro3c      anthro4
   3.3268603    3.6565240    0.5953626    0.0000000
attr(,"offset")
[1] 30.78282

> plot(glm2b, off2int = TRUE)

> plot(glm2b, ylim = range(coef(glm2b, which = preds)))

> par(mar = c(4, 4, 0, 6) + 0.1)

> plot(glm2b, main = "", off2int = TRUE)

> par(mar = c(4, 4, 0, 6) + 0.1)

> plot(glm2b, ylim = range(coef(glm2b, which = preds)),
+     main = "")

> gam1 <- gamboost(DEXfat ~ bbs(hipcirc) + bbs(kneebreadth) +
+     bbs(anthro3a), data = bodyfat)

> par(mfrow = c(1, 3))

> plot(gam1)

> par(mfrow = c(1, 3))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(gam1)

> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs",
+     data = bodyfat, control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 505.0447
[  41] ...................................... -- risk: 428.2663
[  81] ..................
Final risk: 406.6786

> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs",
+     data = bodyfat)

> set.seed(123)

> cvm <- cvrisk(gam2)
Loading required package: multicore

> cvm

	 Cross-validated Squared Error (Regression)
	 gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs")

        1         2         3         4         5         6         7         8
109.44090  93.77936  80.39199  69.39746  60.03652  52.63142  45.98735  40.61891
        9        10        11        12        13        14        15        16
 36.19419  32.43483  29.45696  26.83747  24.87569  23.13113  21.61787  20.37703
       17        18        19        20        21        22        23        24
 19.28041  18.45433  17.75830  17.09118  16.71937  16.34698  16.11248  15.80643
       25        26        27        28        29        30        31        32
 15.68170  15.61957  15.51475  15.44504  15.43898  15.43648  15.47471  15.49106
       33        34        35        36        37        38        39        40
 15.53716  15.59909  15.69337  15.74063  15.79742  15.82627  15.92533  15.96498
       41        42        43        44        45        46        47        48
 16.05951  16.14622  16.15449  16.22718  16.24294  16.36161  16.41389  16.45765
       49        50        51        52        53        54        55        56
 16.53431  16.58332  16.64761  16.68104  16.76672  16.83018  16.87198  16.94478
       57        58        59        60        61        62        63        64
 16.98208  17.03797  17.09194  17.16252  17.19414  17.22933  17.26655  17.33742
       65        66        67        68        69        70        71        72
 17.36385  17.41176  17.46760  17.51569  17.53330  17.58616  17.61561  17.66218
       73        74        75        76        77        78        79        80
 17.69674  17.72085  17.73939  17.81207  17.84139  17.87207  17.91952  17.95899
       81        82        83        84        85        86        87        88
 17.98436  18.00266  18.06980  18.08974  18.12129  18.13717  18.18262  18.21936
       89        90        91        92        93        94        95        96
 18.24584  18.26830  18.28842  18.30035  18.30461  18.34825  18.41183  18.41228
       97        98        99       100
 18.42904  18.44325  18.47198  18.50329

	 Optimal number of boosting iterations: 30

> plot(cvm)

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(cvm, main = "")

> mstop(cvm)
[1] 30

> gam2[mstop(cvm)]

	 Model-based Boosting

Call:
gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs")


	 Squared Error (Regression)

Loss function: (y - f)^2


Number of boosting iterations: mstop = 30
Step size:  0.1
Offset:  30.78282
Number of baselearners:  9


> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs",
+     data = bodyfat, control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 505.0447
[  41] ...................................... -- risk: 428.2663
[  81] ..................
Final risk: 406.6786

> gam2[mstop(cvm)]

	 Model-based Boosting

Call:
gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs",     control = boost_control(trace = TRUE))


	 Squared Error (Regression)

Loss function: (y - f)^2


Number of boosting iterations: mstop = 30
Step size:  0.1
Offset:  30.78282
Number of baselearners:  9


> names(coef(gam2))
[1] "bbs(waistcirc, df = dfbase)"   "bbs(hipcirc, df = dfbase)"
[3] "bbs(kneebreadth, df = dfbase)" "bbs(anthro3a, df = dfbase)"
[5] "bbs(anthro3b, df = dfbase)"    "bbs(anthro3c, df = dfbase)"

> gam2[1000, return = FALSE]
[ 101] ...................................... -- risk: 374.6936
[ 141] ...................................... -- risk: 351.2605
[ 181] ...................................... -- risk: 333.3519
[ 221] ...................................... -- risk: 318.883
[ 261] ...................................... -- risk: 306.9214
[ 301] ...................................... -- risk: 296.7923
[ 341] ...................................... -- risk: 288.0382
[ 381] ...................................... -- risk: 280.3657
[ 421] ...................................... -- risk: 273.5146
[ 461] ...................................... -- risk: 267.3621
[ 501] ...................................... -- risk: 261.7149
[ 541] ...................................... -- risk: 256.5418
[ 581] ...................................... -- risk: 251.7186
[ 621] ...................................... -- risk: 247.224
[ 661] ...................................... -- risk: 243.0014
[ 701] ...................................... -- risk: 238.9041
[ 741] ...................................... -- risk: 234.9688
[ 781] ...................................... -- risk: 231.2079
[ 821] ...................................... -- risk: 227.5621
[ 861] ...................................... -- risk: 224.1102
[ 901] ...................................... -- risk: 220.7802
[ 941] ...................................... -- risk: 217.5494
[ 981] ..................
Final risk: 215.9465
NULL

> names(coef(gam2))
[1] "bbs(age, df = dfbase)"          "bbs(waistcirc, df = dfbase)"
[3] "bbs(hipcirc, df = dfbase)"      "bbs(elbowbreadth, df = dfbase)"
[5] "bbs(kneebreadth, df = dfbase)"  "bbs(anthro3a, df = dfbase)"
[7] "bbs(anthro3b, df = dfbase)"     "bbs(anthro3c, df = dfbase)"
[9] "bbs(anthro4, df = dfbase)"

> glm3 <- glmboost(DEXfat ~ hipcirc + kneebreadth +
+     anthro3a, data = bodyfat, family = QuantReg(tau = 0.5), control = boost_control(mstop = 500 .... [TRUNCATED]

> coef(glm3, off2int = TRUE)
(Intercept)     hipcirc kneebreadth    anthro3a
-63.5164304   0.5331394   0.7699975   7.8350858

> loss = function(y, f) tau * (y - f) * ((y - f) >=
+     0) + (tau - 1) * (y - f) * ((y - f) < 0)

> ngradient = function(y, f, w = 1) tau * ((y - f) >=
+     0) + (tau - 1) * ((y - f) < 0)

> OurQuantReg <- function(tau = 0.5) {
+     Family(loss = function(y, f) tau * (y - f) * ((y - f) >=
+         0) + (tau - 1) * (y - f) * ((y - f) < .... [TRUNCATED]

> OurQuantReg()

	 Our new family for quantile regression

Loss function: tau * (y - f) * ((y - f) >= 0) + (tau - 1) * (y - f) * ((y -
     f) < 0)


> glm3b <- glmboost(DEXfat ~ hipcirc + kneebreadth +
+     anthro3a, data = bodyfat, family = OurQuantReg(tau = 0.5),
+     control = boost_control( .... [TRUNCATED]

> identical(coef(glm3b), coef(glm3))
[1] TRUE

> glm4a <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.05),
+     data = bodyfat, control = boost_control(mstop = 2000))

> glm4b <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.5),
+     data = bodyfat, control = boost_control(mstop = 2000))

> glm4c <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.95),
+     data = bodyfat, control = boost_control(mstop = 2000))

> ord <- order(bodyfat$hipcirc)

> plot(bodyfat$hipcirc[ord], bodyfat$DEXfat[ord])

> lines(bodyfat$hipcirc[ord], fitted(glm4a)[ord], lty = 2,
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4b)[ord], lty = 1,
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4c)[ord], lty = 2,
+     lwd = 2)

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(bodyfat$hipcirc[ord], bodyfat$DEXfat[ord])

> lines(bodyfat$hipcirc[ord], fitted(glm4a)[ord], lty = 2,
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4b)[ord], lty = 1,
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4c)[ord], lty = 2,
+     lwd = 2)

> red <- rgb(103, 0, 31, max = 255)

> library("mboost")

> library("RColorBrewer")

> cols <- paste(brewer.pal(11, "RdBu")[c(10, 2)], "E6",
+     sep = "")

> set.seed(1907)

> x <- rnorm(50, mean = 5)

> y <- rnorm(50, mean = x, sd = 0.3)

> y <- y - mean(y)

> par(ps = 8, cex = 1, cex.lab = 1, mar = c(3.1, 3,
+     0.5, 0.1), mgp = c(2, 1, 0))

> xrange <- range(0, x)

> plot(y ~ x, xlim = xrange, cex = 1, xlab = "x", ylab = "negative gradient in step m = 1",
+     pch = 20, col = rgb(0.5, 0.5, 0.5, alpha = 0.8))

> abline(h = 0, col = "gray", lwd = 0.5)

> abline(v = 0, col = "gray", lwd = 0.5)

> abline(lm(y ~ x - 1), col = cols[1], lwd = 1.5)

> points(0, 0, col = cols[2], lwd = 1.5)

> points(mean(x), mean(y), col = cols[2], pch = 3, lwd = 1.5)

> legend(0.1, 2.35, legend = c("origin", "center of data",
+     "base-learner"), pch = c(21, 3, -1), lty = c(-1, -1, 1),
+     col = c(cols[2], col .... [TRUNCATED]

> set.seed(1907)

> x <- rnorm(50, mean = 5)

> y <- rnorm(50, mean = x, sd = 0.3)

> y <- y - mean(y)

> mx <- mean(x)

> xrange <- range(0, x)

> x <- x - mean(x)

> par(ps = 8, cex = 1, cex.lab = 1, mar = c(3.1, 3,
+     0.5, 0.1), mgp = c(2, 1, 0))

> plot(y ~ x, xlim = xrange - mx, cex = 1, xlab = "x (centered)",
+     ylab = "negative gradient in step m = 1", pch = 20, col = rgb(0.5,
+         .... [TRUNCATED]

> abline(h = 0, col = "gray", lwd = 0.5)

> abline(v = 0, col = "gray", lwd = 0.5)

> abline(lm(y ~ x - 1), col = cols[1], lwd = 1.5)

> points(0, 0, col = cols[2], lwd = 1.5)

> points(mean(x), mean(y), col = cols[2], pch = 3, lwd = 1.5)

> set.seed(1907)

> n <- 100

> x1 <- rnorm(n)

> x2 <- as.factor(sample(0:3, n, replace = TRUE))

> y <- 0.5 * x1 + rnorm(n)

> mod <- gamboost(y ~ bols(x1), control = boost_control(mstop = 25))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x1), (0.5 * x1)[order(x1)], type = "l",
+     lwd = 2, xlab = expression(x[1]), ylab = expression(f(x[1])))

> lines(sort(x1), fitted(mod, which = 1)[order(x1)],
+     col = red, lwd = 2, type = "b", pch = 20)

> legend("topleft", c("true effect", "model"), lty = c(1,
+     1), pch = c(-1, 20), merge = TRUE, lwd = 2, col = c("black",
+     red), bty = "n")

> beta <- c(0, -1, 0.5, 3)

> y <- drop(model.matrix(~x2) %*% beta + rnorm(n, sd = 0.3))

> mod <- gamboost(y ~ bols(x2), control = boost_control(mstop = 50))

> par(mar = c(4, 4, 0, 0) + 0.1)

> betaPred <- coef(mod)[[1]]

> betaPred[1] <- betaPred[1] + attr(coef(mod), "offset")

> betaTrue <- c(0, -1, 0.5, 3)

> plot(1:4, betaPred, type = "n", xaxt = "n", xlab = expression(x[2]),
+     ylab = expression(f(x[2])), xlim = c(0.5, 4.5), ylim = c(-1.5,
+        .... [TRUNCATED]

> axis(1, at = 1:4, labels = expression(x[2]^(1), x[2]^(2),
+     x[2]^(3), x[2]^(4)))

> for (i in 1:4) lines(i + c(-0.38, 0, 0.38), rep(betaPred[i],
+     each = 3), lwd = 2, col = red, type = "b", pch = 20)

> for (i in 1:4) lines(i + c(-0.4, 0.4), rep(betaTrue[i],
+     each = 2), lwd = 2, col = "black")

> legend("topleft", c("true effect", "model"), pch = c(-1,
+     20), lty = c(1, 1), lwd = 2, col = c("black", red), bty = "n")

> set.seed(1907)

> n <- 100

> x1 <- rnorm(n)

> x2 <- rnorm(n) + 0.25 * x1

> x3 <- as.factor(sample(0:1, n, replace = TRUE))

> x4 <- gl(4, 25)

> y <- 3 * sin(x1) + x2^2 + rnorm(n)

> knots.x2 <- quantile(x2, c(0.25, 0.5, 0.75))

> mod <- gamboost(y ~ bbs(x1, knots = 20, df = 4) +
+     bbs(x2, knots = knots.x2, df = 5) + bols(x3) + bols(x4))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x1), (3 * sin(x1))[order(x1)], type = "l",
+     lwd = 2, xlab = expression(x[1]), ylab = expression(f[1](x[1])))

> lines(sort(x1), fitted(mod, which = 1)[order(x1)],
+     col = red, lwd = 2, type = "b", pch = 20)

> legend("topleft", c("true effect", "model"), lty = c(1,
+     1), pch = c(-1, 20), merge = TRUE, lwd = 2, col = c("black",
+     red), bty = "n")

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x2), (x2^2)[order(x2)], type = "l", lwd = 2,
+     xlab = expression(x[2]), ylab = expression(f[2](x[2])))

> lines(sort(x2), fitted(mod, which = 2)[order(x2)] +
+     mod$offset, col = red, lwd = 2, type = "b", pch = 20)

> set.seed(1907)

> x <- runif(200, 0, (2 * pi))

> y <- rnorm(200, mean = sin(x), sd = 0.2)

> newX <- seq(0, 2 * pi, length = 100)

> mod <- gamboost(y ~ bbs(x, knots = 12))

> mod_cyclic <- gamboost(y ~ bbs(x, cyclic = TRUE, knots = 12,
+     boundary.knots = c(0, 2 * pi)))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(x, y, ylab = "f(x)", cex = 1, pch = 20, col = rgb(0.5,
+     0.5, 0.5, alpha = 0.8))

> lines(newX, predict(mod, data.frame(x = newX)), col = "black",
+     lwd = 2)
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases

> lines(newX + 2 * pi, predict(mod, data.frame(x = newX)),
+     col = "black", lwd = 2)
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases

> legend("bottomleft", c("cyclic = FALSE"), lty = c(1),
+     col = c("black"), lwd = 2, bty = "n")

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(x, y, ylab = "f(x)", cex = 1, pch = 20, col = rgb(0.5,
+     0.5, 0.5, alpha = 0.8))

> lines(newX, predict(mod_cyclic, data.frame(x = newX)),
+     col = red, lwd = 2)

> lines(newX + 2 * pi, predict(mod_cyclic, data.frame(x = newX)),
+     col = red, lwd = 2)

> abline(v = 2 * pi, col = "gray", lty = "dashed", lwd = 2)

> legend("bottomleft", c("cyclic = TRUE"), lty = c(1),
+     col = c(red), lwd = 2, bty = "n")

> set.seed(1907)

> x1 <- runif(250, -pi, pi)

> x2 <- runif(250, -pi, pi)

> y <- sin(x1) * sin(x2) + rnorm(250, sd = 0.4)

> modspa <- gamboost(y ~ bspatial(x1, x2, knots = list(x1 = 12,
+     x2 = 12)))
Note: Method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dgCMatrix#dgTMatrix'.
 "sparseMatrix#TsparseMatrix" would also be valid
Note: Method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dgTMatrix#dgCMatrix'.
 "TsparseMatrix#sparseMatrix" would also be valid
Note: Method with signature 'Matrix#diagonalMatrix' chosen for function 'kronecker',
 target signature 'dsCMatrix#ddiMatrix'.
 "sparseMatrix#ANY" would also be valid
Note: Method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dsCMatrix#dtTMatrix'.
 "sparseMatrix#TsparseMatrix" would also be valid
Note: Method with signature 'diagonalMatrix#Matrix' chosen for function 'kronecker',
 target signature 'ddiMatrix#dsCMatrix'.
 "ANY#sparseMatrix" would also be valid
Note: Method with signature 'dsparseMatrix#dsparseMatrix' chosen for function 'kronecker',
 target signature 'dtTMatrix#dsCMatrix'.
 "TsparseMatrix#sparseMatrix" would also be valid

> library(lattice)

Attaching package: ‘lattice’

The following object(s) are masked from ‘package:multicore’:

    parallel


> library(RColorBrewer)

> nCols <- 50

> cols <- colorRampPalette(rev(brewer.pal(11, "RdBu")),
+     space = "Lab", interpolate = "spline")(nCols)

> nd <- expand.grid(x1 = seq(-pi, pi, length = 100),
+     x2 = seq(-pi, pi, length = 100))

> preds <- predict(modspa, newdata = nd)
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases

> breaks <- seq(min(preds), max(preds), length = nCols +
+     1)

> print(levelplot(preds ~ nd$x1 + nd$x2, xlab = expression(x[1]),
+     ylab = expression(x[2]), at = breaks, col.regions = cols,
+     cex = 0.7, c .... [TRUNCATED]

> x1 <- x2 <- seq(-pi, pi, length = 50)

> nd <- expand.grid(x1 = x1, x2 = x2)

> preds <- predict(modspa, newdata = nd)
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases
Warning in bs(mf[[i]], knots = args$knots[[i]]$knots, degree = args$degree,  :
  some 'x' values beyond boundary knots may cause ill-conditioned bases

> z <- matrix(preds, ncol = length(x1))

> nrz <- nrow(z)

> ncz <- ncol(z)

> jet.colors <- colorRampPalette(paste(brewer.pal(11,
+     "RdBu")[c(10, 2)], "E6", sep = ""))

> nbcol <- 10

> color <- jet.colors(nbcol)

> zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] +
+     z[-nrz, -ncz]

> facetcol <- cut(zfacet, nbcol)

> par(mar = c(1, 0.1, 0.1, 0.1), mgp = c(1.8, 1, 0))

> persp(x1, x2, z, theta = 45, phi = 30, expand = 0.5,
+     col = color[facetcol], ticktype = "detailed", nticks = 3,
+     xlab = "x1", ylab = "x2 ..." ... [TRUNCATED]

> pdf("./graphics/fig-family.pdf", width = 5, height = 4)

> par(mar = c(4, 4, 0, 0) + 0.1)

> x <- seq(-2, 2, length = 200)

> plot(x, x^2, type = "l", ylab = expression(rho), xlab = expression(y -
+     f))

> x <- seq(-2, 2, length = 200)

> lossL1 <- function(x, param) abs(x)

> mp <- 0.5

> dat <- data.frame(x = rep(x, length(mp)), y = as.numeric(sapply(mp,
+     function(z) lossL1(x, param = z))), param = rep(mp, each = length(x)))

> dat$tau <- factor(dat$param)

> plot(x, dat$y, type = "l", ylab = expression(rho),
+     xlab = expression(y - f))

> x <- seq(-2, 2, length = 200)

> lossH <- function(x, param) ifelse(abs(x) <= param,
+     (1/2) * x^2, param * (abs(x) - param/2))

> mp <- c(0.2, 0.5, 1, 2, 10)

> dat <- data.frame(x = x, sapply(mp, function(z) lossH(x,
+     param = z)))

> plot(x, dat$X1, type = "l", ylim = c(0, 2), ylab = expression(rho),
+     xlab = expression(y - f))

> legend(0, 2, xjust = 0.5, legend = paste(mp), title = expression(delta),
+     lty = 1, col = c(1, 3, 4, 5, 6), cex = 0.6, box.col = "gray")

> for (i in 1:(length(mp) - 1)) {
+     lines(x, dat[, i + 2], col = i + 2)
+ }

> x <- seq(-2, 2, length = 200)

> lossL1 <- function(x, param) ifelse(x >= 0, param *
+     x, (param - 1) * x)

> mp <- c(5:9/10)

> dat <- data.frame(x = x, sapply(mp, function(z) lossL1(x,
+     param = z)))

> plot(x, dat$X1, type = "l", ylab = expression(rho),
+     ylim = c(0, 2), xlab = expression(y - f))

> legend(0, 2, xjust = 0.5, legend = paste(mp), title = expression(tau),
+     lty = 1, col = c(1, 3, 4, 5, 6), cex = 0.6, box.col = "gray")

> for (i in 1:(length(mp) - 1)) {
+     lines(x, dat[, i + 2], col = i + 2)
+ }

> x <- seq(-2, 2, length = 200)

> dat <- data.frame(x = x, Binomial = log(1 + exp(-2 *
+     x), base = 2), AdaExp = exp(-x))

> plot(x, dat$Binomial, type = "l", lty = 1, col = 1,
+     xlab = expression(tilde(y) * f), ylab = expression(rho),
+     ylim = c(0, 7.5))

> lines(x, dat$AdaExp, lty = 2, col = 2)

> legend("topright", legend = c("Binomial", "AdaExp"),
+     xjust = 0.5, title = "loss", lty = 1:2, col = 1:2, cex = 0.8,
+     bty = "n")

> dev.off()
pdf
  2

 *** Run successfully completed ***
