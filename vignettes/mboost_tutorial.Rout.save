
R version 2.15.2 (2012-10-26) -- "Trick or Treat"
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu verbreiten.
Tippen Sie 'license()' or 'licence()' für Details dazu.

R ist ein Gemeinschaftsprojekt mit vielen Beitragenden.
Tippen Sie 'contributors()' für mehr Information und 'citation()',
um zu erfahren, wie R oder R packages in Publikationen zitiert werden können.

Tippen Sie 'demo()' für einige Demos, 'help()' für on-line Hilfe, oder
'help.start()' für eine HTML Browserschnittstelle zur Hilfe.
Tippen Sie 'q()', um R zu verlassen.

> tools:::.run_one_vignette("mboost_tutorial.Rnw", docDir = ".");

> options(prompt = "R> ", continue = "+  ", width = 80)

> pd <- packageDescription("mboost")

> if (any(is.na(pd))) {
+     install.packages("mboost", repos = "http://cran.at.r-project.org")
+     pd <- packageDescription("mboost")
+  .... [TRUNCATED] 

> if (compareVersion(pd$Version, "2.1-0") < 0) {
+     warning("Current version of mboost is installed!")
+     install.packages("mboost", repos  .... [TRUNCATED] 

> require("mboost")

> set.seed(190781)

> if (!file.exists("graphics")) dir.create("graphics")

> library("mboost")

> data("bodyfat")

> lm1 <- lm(DEXfat ~ hipcirc + kneebreadth + anthro3a, 
+     data = bodyfat)

> coef(lm1)
(Intercept)     hipcirc kneebreadth    anthro3a 
-75.2347840   0.5115264   1.9019904   8.9096375 

> glm1 <- glmboost(DEXfat ~ hipcirc + kneebreadth + 
+     anthro3a, data = bodyfat)

> coef(glm1, off2int = TRUE)
(Intercept)     hipcirc kneebreadth    anthro3a 
-75.2073365   0.5114861   1.9005386   8.9071301 

> preds <- names(bodyfat[, names(bodyfat) != "DEXfat"])

> fm <- as.formula(paste("DEXfat ~", paste(preds, collapse = "+")))

> fm
DEXfat ~ age + waistcirc + hipcirc + elbowbreadth + kneebreadth + 
    anthro3a + anthro3b + anthro3c + anthro4

> glm2a <- glmboost(fm, data = bodyfat)

> glm2b <- glmboost(DEXfat ~ ., data = bodyfat)

> identical(coef(glm2a), coef(glm2b))
[1] TRUE

> coef(glm2b, which = "")
 (Intercept)          age    waistcirc      hipcirc elbowbreadth  kneebreadth 
 -98.8166077    0.0136017    0.1897156    0.3516258   -0.3841399    1.7365888 
    anthro3a     anthro3b     anthro3c      anthro4 
   3.3268603    3.6565240    0.5953626    0.0000000 
attr(,"offset")
[1] 30.78282

> plot(glm2b, off2int = TRUE)

> plot(glm2b, ylim = range(coef(glm2b, which = preds)))

> par(mar = c(4, 4, 0, 6) + 0.1)

> plot(glm2b, main = "", off2int = TRUE)

> par(mar = c(4, 4, 0, 6) + 0.1)

> plot(glm2b, ylim = range(coef(glm2b, which = preds)), 
+     main = "")

> gam1 <- gamboost(DEXfat ~ bbs(hipcirc) + bbs(kneebreadth) + 
+     bbs(anthro3a), data = bodyfat)

> par(mfrow = c(1, 3))

> plot(gam1)

> par(mfrow = c(1, 3))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(gam1)

> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs", 
+     data = bodyfat, control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 544.4295 
[  41] ...................................... -- risk: 478.6167 
[  81] ..................
Final risk: 460.343 

> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs", 
+     data = bodyfat)

> set.seed(123)

> cvm <- cvrisk(gam2)

> cvm

	 Cross-validated Squared Error (Regression) 
	 gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs") 

        1         2         3         4         5         6         7         8 
109.44043  93.90510  80.59096  69.60200  60.13397  52.59479  46.11235  40.80175 
        9        10        11        12        13        14        15        16 
 36.32637  32.66942  29.66258  27.07809  24.99304  23.11263  21.55970  20.40313 
       17        18        19        20        21        22        23        24 
 19.16541  18.31613  17.59806  16.96801  16.48827  16.07595  15.75689  15.47100 
       25        26        27        28        29        30        31        32 
 15.21898  15.06787  14.96986  14.86724  14.80542  14.74726  14.68165  14.68648 
       33        34        35        36        37        38        39        40 
 14.64315  14.67862  14.68193  14.68394  14.75454  14.80268  14.81760  14.87570 
       41        42        43        44        45        46        47        48 
 14.90511  14.92398  15.00389  15.03604  15.07639  15.10671  15.15364  15.20770 
       49        50        51        52        53        54        55        56 
 15.23825  15.30189  15.31950  15.35630  15.41134  15.46079  15.49545  15.53137 
       57        58        59        60        61        62        63        64 
 15.57602  15.61894  15.66218  15.71172  15.72119  15.75424  15.80828  15.84097 
       65        66        67        68        69        70        71        72 
 15.89077  15.90547  15.93003  15.95715  15.99073  16.03679  16.06174  16.10615 
       73        74        75        76        77        78        79        80 
 16.12734  16.15830  16.18715  16.22298  16.27167  16.27686  16.30944  16.33804 
       81        82        83        84        85        86        87        88 
 16.36836  16.39441  16.41587  16.43615  16.44862  16.48259  16.51989  16.52985 
       89        90        91        92        93        94        95        96 
 16.54723  16.58531  16.61028  16.61020  16.62380  16.64316  16.64343  16.68386 
       97        98        99       100 
 16.69995  16.73360  16.74944  16.75756 

	 Optimal number of boosting iterations: 33 

> plot(cvm)

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(cvm, main = "")

> mstop(cvm)
[1] 33

> gam2[mstop(cvm)]

	 Model-based Boosting

Call:
gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs")


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 33 
Step size:  0.1 
Offset:  30.78282 
Number of baselearners:  9 


> gam2 <- gamboost(DEXfat ~ ., baselearner = "bbs", 
+     data = bodyfat, control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 544.4295 
[  41] ...................................... -- risk: 478.6167 
[  81] ..................
Final risk: 460.343 

> gam2[mstop(cvm)]

	 Model-based Boosting

Call:
gamboost(formula = DEXfat ~ ., data = bodyfat, baselearner = "bbs",     control = boost_control(trace = TRUE))


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 33 
Step size:  0.1 
Offset:  30.78282 
Number of baselearners:  9 


> names(coef(gam2))
[1] "bbs(waistcirc, df = dfbase)"   "bbs(hipcirc, df = dfbase)"    
[3] "bbs(kneebreadth, df = dfbase)" "bbs(anthro3a, df = dfbase)"   
[5] "bbs(anthro3b, df = dfbase)"    "bbs(anthro3c, df = dfbase)"   
[7] "bbs(anthro4, df = dfbase)"    

> gam2[1000, return = FALSE]
[ 101] ...................................... -- risk: 431.3254 
[ 141] ...................................... -- risk: 408.7952 
[ 181] ...................................... -- risk: 390.5753 
[ 221] ...................................... -- risk: 375.6194 
[ 261] ...................................... -- risk: 363.12 
[ 301] ...................................... -- risk: 352.3364 
[ 341] ...................................... -- risk: 342.9405 
[ 381] ...................................... -- risk: 334.5222 
[ 421] ...................................... -- risk: 326.9719 
[ 461] ...................................... -- risk: 320.1967 
[ 501] ...................................... -- risk: 313.9576 
[ 541] ...................................... -- risk: 308.2658 
[ 581] ...................................... -- risk: 302.9771 
[ 621] ...................................... -- risk: 298.0882 
[ 661] ...................................... -- risk: 293.5637 
[ 701] ...................................... -- risk: 289.2967 
[ 741] ...................................... -- risk: 285.3045 
[ 781] ...................................... -- risk: 281.5391 
[ 821] ...................................... -- risk: 277.9986 
[ 861] ...................................... -- risk: 274.6487 
[ 901] ...................................... -- risk: 271.4487 
[ 941] ...................................... -- risk: 268.4307 
[ 981] ..................
Final risk: 266.9768 
NULL

> names(coef(gam2))
[1] "bbs(age, df = dfbase)"          "bbs(waistcirc, df = dfbase)"   
[3] "bbs(hipcirc, df = dfbase)"      "bbs(elbowbreadth, df = dfbase)"
[5] "bbs(kneebreadth, df = dfbase)"  "bbs(anthro3a, df = dfbase)"    
[7] "bbs(anthro3b, df = dfbase)"     "bbs(anthro3c, df = dfbase)"    
[9] "bbs(anthro4, df = dfbase)"     

> glm3 <- glmboost(DEXfat ~ hipcirc + kneebreadth + 
+     anthro3a, data = bodyfat, family = QuantReg(tau = 0.5), control = boost_control(mstop = 500 .... [TRUNCATED] 

> coef(glm3, off2int = TRUE)
(Intercept)     hipcirc kneebreadth    anthro3a 
-63.5164304   0.5331394   0.7699975   7.8350858 

> loss = function(y, f) tau * (y - f) * ((y - f) >= 
+     0) + (tau - 1) * (y - f) * ((y - f) < 0)

> ngradient = function(y, f, w = 1) tau * ((y - f) >= 
+     0) + (tau - 1) * ((y - f) < 0)

> OurQuantReg <- function(tau = 0.5) {
+     Family(loss = function(y, f) tau * (y - f) * ((y - f) >= 
+         0) + (tau - 1) * (y - f) * ((y - f) < .... [TRUNCATED] 

> OurQuantReg()

	 Our new family for quantile regression 

Loss function: tau * (y - f) * ((y - f) >= 0) + (tau - 1) * (y - f) * ((y -  
     f) < 0) 
 

> glm3b <- glmboost(DEXfat ~ hipcirc + kneebreadth + 
+     anthro3a, data = bodyfat, family = OurQuantReg(tau = 0.5), 
+     control = boost_control( .... [TRUNCATED] 

> identical(coef(glm3b), coef(glm3))
[1] TRUE

> glm4a <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.05), 
+     data = bodyfat, control = boost_control(mstop = 2000))

> glm4b <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.5), 
+     data = bodyfat, control = boost_control(mstop = 2000))

> glm4c <- glmboost(DEXfat ~ hipcirc, family = OurQuantReg(tau = 0.95), 
+     data = bodyfat, control = boost_control(mstop = 2000))

> ord <- order(bodyfat$hipcirc)

> plot(bodyfat$hipcirc[ord], bodyfat$DEXfat[ord])

> lines(bodyfat$hipcirc[ord], fitted(glm4a)[ord], lty = 2, 
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4b)[ord], lty = 1, 
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4c)[ord], lty = 2, 
+     lwd = 2)

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(bodyfat$hipcirc[ord], bodyfat$DEXfat[ord])

> lines(bodyfat$hipcirc[ord], fitted(glm4a)[ord], lty = 2, 
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4b)[ord], lty = 1, 
+     lwd = 2)

> lines(bodyfat$hipcirc[ord], fitted(glm4c)[ord], lty = 2, 
+     lwd = 2)

> red <- rgb(103, 0, 31, max = 255)

> library("mboost")

> library("RColorBrewer")

> cols <- paste(brewer.pal(11, "RdBu")[c(10, 2)], "E6", 
+     sep = "")

> set.seed(1907)

> x <- rnorm(50, mean = 5)

> y <- rnorm(50, mean = x, sd = 0.3)

> y <- y - mean(y)

> par(ps = 8, cex = 1, cex.lab = 1, mar = c(3.1, 3, 
+     0.5, 0.1), mgp = c(2, 1, 0))

> xrange <- range(0, x)

> plot(y ~ x, xlim = xrange, cex = 1, xlab = "x", ylab = "negative gradient in step m = 1", 
+     pch = 20, col = rgb(0.5, 0.5, 0.5, alpha = 0.8))

> abline(h = 0, col = "gray", lwd = 0.5)

> abline(v = 0, col = "gray", lwd = 0.5)

> abline(lm(y ~ x - 1), col = cols[1], lwd = 1.5)

> points(0, 0, col = cols[2], lwd = 1.5)

> points(mean(x), mean(y), col = cols[2], pch = 3, lwd = 1.5)

> legend(0.1, 2.35, legend = c("origin", "center of data", 
+     "base-learner"), pch = c(21, 3, -1), lty = c(-1, -1, 1), 
+     col = c(cols[2], col .... [TRUNCATED] 

> set.seed(1907)

> x <- rnorm(50, mean = 5)

> y <- rnorm(50, mean = x, sd = 0.3)

> y <- y - mean(y)

> mx <- mean(x)

> xrange <- range(0, x)

> x <- x - mean(x)

> par(ps = 8, cex = 1, cex.lab = 1, mar = c(3.1, 3, 
+     0.5, 0.1), mgp = c(2, 1, 0))

> plot(y ~ x, xlim = xrange - mx, cex = 1, xlab = "x (centered)", 
+     ylab = "negative gradient in step m = 1", pch = 20, col = rgb(0.5, 
+         .... [TRUNCATED] 

> abline(h = 0, col = "gray", lwd = 0.5)

> abline(v = 0, col = "gray", lwd = 0.5)

> abline(lm(y ~ x - 1), col = cols[1], lwd = 1.5)

> points(0, 0, col = cols[2], lwd = 1.5)

> points(mean(x), mean(y), col = cols[2], pch = 3, lwd = 1.5)

> set.seed(1907)

> n <- 100

> x1 <- rnorm(n)

> x2 <- as.factor(sample(0:3, n, replace = TRUE))

> y <- 0.5 * x1 + rnorm(n)

> mod <- gamboost(y ~ bols(x1), control = boost_control(mstop = 25))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x1), (0.5 * x1)[order(x1)], type = "l", 
+     lwd = 2, xlab = expression(x[1]), ylab = expression(f(x[1])))

> lines(sort(x1), fitted(mod, which = 1)[order(x1)], 
+     col = red, lwd = 2, type = "b", pch = 20)

> legend("topleft", c("true effect", "model"), lty = c(1, 
+     1), pch = c(-1, 20), merge = TRUE, lwd = 2, col = c("black", 
+     red), bty = "n")

> beta <- c(0, -1, 0.5, 3)

> y <- drop(model.matrix(~x2) %*% beta + rnorm(n, sd = 0.3))

> mod <- gamboost(y ~ bols(x2), control = boost_control(mstop = 50))

> par(mar = c(4, 4, 0, 0) + 0.1)

> betaPred <- coef(mod)[[1]]

> betaPred[1] <- betaPred[1] + attr(coef(mod), "offset")

> betaTrue <- c(0, -1, 0.5, 3)

> plot(1:4, betaPred, type = "n", xaxt = "n", xlab = expression(x[2]), 
+     ylab = expression(f(x[2])), xlim = c(0.5, 4.5), ylim = c(-1.5, 
+        .... [TRUNCATED] 

> axis(1, at = 1:4, labels = expression(x[2]^(1), x[2]^(2), 
+     x[2]^(3), x[2]^(4)))

> for (i in 1:4) lines(i + c(-0.38, 0, 0.38), rep(betaPred[i], 
+     each = 3), lwd = 2, col = red, type = "b", pch = 20)

> for (i in 1:4) lines(i + c(-0.4, 0.4), rep(betaTrue[i], 
+     each = 2), lwd = 2, col = "black")

> legend("topleft", c("true effect", "model"), pch = c(-1, 
+     20), lty = c(1, 1), lwd = 2, col = c("black", red), bty = "n")

> set.seed(1907)

> n <- 100

> x1 <- rnorm(n)

> x2 <- rnorm(n) + 0.25 * x1

> x3 <- as.factor(sample(0:1, n, replace = TRUE))

> x4 <- gl(4, 25)

> y <- 3 * sin(x1) + x2^2 + rnorm(n)

> knots.x2 <- quantile(x2, c(0.25, 0.5, 0.75))

> mod <- gamboost(y ~ bbs(x1, knots = 20, df = 4) + 
+     bbs(x2, knots = knots.x2, df = 5) + bols(x3) + bols(x4))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x1), (3 * sin(x1))[order(x1)], type = "l", 
+     lwd = 2, xlab = expression(x[1]), ylab = expression(f[1](x[1])))

> lines(sort(x1), fitted(mod, which = 1)[order(x1)], 
+     col = red, lwd = 2, type = "b", pch = 20)

> legend("topleft", c("true effect", "model"), lty = c(1, 
+     1), pch = c(-1, 20), merge = TRUE, lwd = 2, col = c("black", 
+     red), bty = "n")

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(sort(x2), (x2^2)[order(x2)], type = "l", lwd = 2, 
+     xlab = expression(x[2]), ylab = expression(f[2](x[2])))

> lines(sort(x2), fitted(mod, which = 2)[order(x2)] + 
+     mod$offset, col = red, lwd = 2, type = "b", pch = 20)

> set.seed(1907)

> x <- runif(200, 0, (2 * pi))

> y <- rnorm(200, mean = sin(x), sd = 0.2)

> newX <- seq(0, 2 * pi, length = 100)

> mod <- gamboost(y ~ bbs(x, knots = 12))

> mod_cyclic <- gamboost(y ~ bbs(x, cyclic = TRUE, knots = 12, 
+     boundary.knots = c(0, 2 * pi)))

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(x, y, ylab = "f(x)", cex = 1, pch = 20, col = rgb(0.5, 
+     0.5, 0.5, alpha = 0.8))

> lines(newX, predict(mod, data.frame(x = newX)), col = "black", 
+     lwd = 2)

> lines(newX + 2 * pi, predict(mod, data.frame(x = newX)), 
+     col = "black", lwd = 2)

> legend("bottomleft", c("cyclic = FALSE"), lty = c(1), 
+     col = c("black"), lwd = 2, bty = "n")

> par(mar = c(4, 4, 0, 0) + 0.1)

> plot(x, y, ylab = "f(x)", cex = 1, pch = 20, col = rgb(0.5, 
+     0.5, 0.5, alpha = 0.8))

> lines(newX, predict(mod_cyclic, data.frame(x = newX)), 
+     col = red, lwd = 2)

> lines(newX + 2 * pi, predict(mod_cyclic, data.frame(x = newX)), 
+     col = red, lwd = 2)

> abline(v = 2 * pi, col = "gray", lty = "dashed", lwd = 2)

> legend("bottomleft", c("cyclic = TRUE"), lty = c(1), 
+     col = c(red), lwd = 2, bty = "n")

> set.seed(1907)

> x1 <- runif(250, -pi, pi)

> x2 <- runif(250, -pi, pi)

> y <- sin(x1) * sin(x2) + rnorm(250, sd = 0.4)

> modspa <- gamboost(y ~ bspatial(x1, x2, knots = list(x1 = 12, 
+     x2 = 12)))

> library(lattice)

> library(RColorBrewer)

> nCols <- 50

> cols <- colorRampPalette(rev(brewer.pal(11, "RdBu")), 
+     space = "Lab", interpolate = "spline")(nCols)

> nd <- expand.grid(x1 = seq(-pi, pi, length = 100), 
+     x2 = seq(-pi, pi, length = 100))

> preds <- predict(modspa, newdata = nd)

> breaks <- seq(min(preds), max(preds), length = nCols + 
+     1)

> print(levelplot(preds ~ nd$x1 + nd$x2, xlab = expression(x[1]), 
+     ylab = expression(x[2]), at = breaks, col.regions = cols, 
+     cex = 0.7, c .... [TRUNCATED] 

> x1 <- x2 <- seq(-pi, pi, length = 50)

> nd <- expand.grid(x1 = x1, x2 = x2)

> preds <- predict(modspa, newdata = nd)

> z <- matrix(preds, ncol = length(x1))

> nrz <- nrow(z)

> ncz <- ncol(z)

> jet.colors <- colorRampPalette(paste(brewer.pal(11, 
+     "RdBu")[c(10, 2)], "E6", sep = ""))

> nbcol <- 10

> color <- jet.colors(nbcol)

> zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + 
+     z[-nrz, -ncz]

> facetcol <- cut(zfacet, nbcol)

> par(mar = c(1, 0.1, 0.1, 0.1), mgp = c(1.8, 1, 0))

> persp(x1, x2, z, theta = 45, phi = 30, expand = 0.5, 
+     col = color[facetcol], ticktype = "detailed", nticks = 3, 
+     xlab = "x1", ylab = "x2 ..." ... [TRUNCATED] 

> pdf("./graphics/fig-family.pdf", width = 5, height = 4)

> par(mar = c(4, 4, 0, 0) + 0.1)

> x <- seq(-2, 2, length = 200)

> plot(x, x^2, type = "l", ylab = expression(rho), xlab = expression(y - 
+     f))

> x <- seq(-2, 2, length = 200)

> lossL1 <- function(x, param) abs(x)

> mp <- 0.5

> dat <- data.frame(x = rep(x, length(mp)), y = as.numeric(sapply(mp, 
+     function(z) lossL1(x, param = z))), param = rep(mp, each = length(x)))

> dat$tau <- factor(dat$param)

> plot(x, dat$y, type = "l", ylab = expression(rho), 
+     xlab = expression(y - f))

> x <- seq(-2, 2, length = 200)

> lossH <- function(x, param) ifelse(abs(x) <= param, 
+     (1/2) * x^2, param * (abs(x) - param/2))

> mp <- c(0.2, 0.5, 1, 2, 10)

> dat <- data.frame(x = x, sapply(mp, function(z) lossH(x, 
+     param = z)))

> plot(x, dat$X1, type = "l", ylim = c(0, 2), ylab = expression(rho), 
+     xlab = expression(y - f))

> legend(0, 2, xjust = 0.5, legend = paste(mp), title = expression(delta), 
+     lty = 1, col = c(1, 3, 4, 5, 6), cex = 0.6, box.col = "gray")

> for (i in 1:(length(mp) - 1)) {
+     lines(x, dat[, i + 2], col = i + 2)
+ }

> x <- seq(-2, 2, length = 200)

> lossL1 <- function(x, param) ifelse(x >= 0, param * 
+     x, (param - 1) * x)

> mp <- c(5:9/10)

> dat <- data.frame(x = x, sapply(mp, function(z) lossL1(x, 
+     param = z)))

> plot(x, dat$X1, type = "l", ylab = expression(rho), 
+     ylim = c(0, 2), xlab = expression(y - f))

> legend(0, 2, xjust = 0.5, legend = paste(mp), title = expression(tau), 
+     lty = 1, col = c(1, 3, 4, 5, 6), cex = 0.6, box.col = "gray")

> for (i in 1:(length(mp) - 1)) {
+     lines(x, dat[, i + 2], col = i + 2)
+ }

> x <- seq(-2, 2, length = 200)

> dat <- data.frame(x = x, Binomial = log(1 + exp(-2 * 
+     x), base = 2), AdaExp = exp(-x))

> plot(x, dat$Binomial, type = "l", lty = 1, col = 1, 
+     xlab = expression(tilde(y) * f), ylab = expression(rho), 
+     ylim = c(0, 7.5))

> lines(x, dat$AdaExp, lty = 2, col = 2)

> legend("topright", legend = c("Binomial", "AdaExp"), 
+     xjust = 0.5, title = "loss", lty = 1:2, col = 1:2, cex = 0.8, 
+     bty = "n")

> dev.off()
pdf 
  2 

 *** Run successfully completed ***
R> 
