
> source("setup.R")
Loading required package: parallel
Loading required package: stabs


	%%%% DON'T EDIT THIS FILE

\setkeys{Gin}{width = 0.95\textwidth}
> if (!require("TH.data")) stop("cannot attach package ", 
+     sQuote("TH.data"))
Loading required package: TH.data
Loading required package: survival
Loading required package: MASS

Attaching package: ‘TH.data’

The following object is masked from ‘package:MASS’:

    geyser


> if (!require("rpart")) stop("cannot attach package ", 
+     sQuote("rpart"))
Loading required package: rpart

> if (!require("survival")) stop("cannot attach package ", 
+     sQuote("survival"))

> if (!require("partykit")) stop("cannot attach package ", 
+     sQuote("partykit"))
Loading required package: partykit
Loading required package: grid
Loading required package: libcoin
Loading required package: mvtnorm

Attaching package: ‘partykit’

The following object is masked from ‘package:mboost’:

    varimp


> set.seed(290875)

> CEX <- 0.85

> options(digits = 3)

> mdplot <- function(obs, pred, main = "", ...) {
+     m <- (obs + pred)/2
+     d <- obs - pred
+     plot(m, d, xlab = "(Observed + Predicted) / 2" .... [TRUNCATED] 

> load(file.path(path.package(package = "TH.data"), 
+     "rda", "AML_Bullinger.rda"))

> AMLw <- IPCweights(Surv(clinical$time, clinical$event))

> risk <- rep(0, nrow(clinical))

> rlev <- levels(clinical[, "Cytogenetic.group"])

> risk[clinical[, "Cytogenetic.group"] %in% rlev[c(7, 
+     8, 4)]] <- "low"

> risk[clinical[, "Cytogenetic.group"] %in% rlev[c(5, 
+     9)]] <- "intermediate"

> risk[clinical[, "Cytogenetic.group"] %in% rlev[-c(4, 
+     5, 7, 8, 9)]] <- "high"

> risk <- as.factor(risk)

> AMLlearn <- cbind(clinical[, c("time", "Sex", "Age", 
+     "LDH", "WBC", "FLT3.aberration.", "MLL.PTD", "Tx.Group.")], 
+     risk = risk, iexpress .... [TRUNCATED] 

> cc <- complete.cases(AMLlearn)

> AMLlearn <- AMLlearn[AMLw > 0 & cc, ]

> AMLw <- AMLw[AMLw > 0 & cc]

> ctrl <- ctree_control(testtype = "Teststatistic", 
+     teststat = "maximum", mincriterion = 0.1, minsplit = 5)

> AMLrf <- cforest(log(time) ~ ., data = AMLlearn, control = ctrl, 
+     weights = AMLw, mtry = 5, ntree = 250, perturb = list(replace = TRUE, 
+     .... [TRUNCATED] 

> AMLl2b <- glmboost(I(log(time)) ~ ., data = AMLlearn, 
+     weights = AMLw, control = boost_control(mstop = 5000))

> plot(aic <- AIC(AMLl2b))

> AMLl2b <- AMLl2b[mstop(aic)]

> cAML <- coef(AMLl2b)

> cAML[abs(cAML) > 0]
    (Intercept)             Age             WBC 
        0.56429         0.00598        -0.00562 
     MLL.PTDyes   Tx.Group.AUTO    Tx.Group.Ind 
       -0.31539         0.45430        -2.12161 
 `IMAGE:145643`  `IMAGE:345601`  `IMAGE:377560` 
        0.10626         0.00430         0.02757 
`IMAGE:2043415` `IMAGE:1584563`  `IMAGE:347035` 
        0.05509        -0.00259        -0.00848 
 `IMAGE:262695`   `IMAGE:26418`  `IMAGE:950479` 
        0.02696         0.00802         0.03717 
`IMAGE:1534700` `IMAGE:1472689` `IMAGE:1526826` 
        0.02836         0.02256        -0.02784 
 `IMAGE:786302`  `IMAGE:243614`  `IMAGE:417884` 
        0.04493        -0.05667        -0.02489 
`IMAGE:1592006`  `IMAGE:884333`  `IMAGE:133273` 
       -0.03551         0.01281         0.02579 
 `IMAGE:950888`  `IMAGE:809533`   `IMAGE:49389` 
        0.03485        -0.05835         0.12105 
 `IMAGE:856174`  `IMAGE:435036`  `IMAGE:491751` 
        0.02054         0.06202         0.11555 
 `IMAGE:782835`   `IMAGE:52930` `IMAGE:2545705` 
       -0.11085        -0.02452        -0.07884 
 `IMAGE:756405`  `IMAGE:129032` `IMAGE:1610168` 
        0.00853        -0.11582         0.01380 
  `IMAGE:69002` `IMAGE:2019101` `IMAGE:1456160` 
       -0.27933        -0.09666        -0.10415 
`IMAGE:2566064`  `IMAGE:565083`  `IMAGE:843028` 
        0.01547         0.18756         0.06983 
  `IMAGE:68794`  `IMAGE:488505`  `IMAGE:291756` 
        0.07614         0.27846         0.09949 
 `IMAGE:810801` `IMAGE:1702742`  `IMAGE:380462` 
        0.04659        -0.01045        -0.09573 
 `IMAGE:154472`  `IMAGE:302540`  `IMAGE:135221` 
       -0.14547         0.01888        -0.03668 
`IMAGE:1567220` 
        0.04851 

> AMLprf <- predict(AMLrf, newdata = AMLlearn)

> AMLpb <- predict(AMLl2b, newdata = AMLlearn)

> Mmod <- sum(AMLw * log(AMLlearn$time))/sum(AMLw)

> par(mai = par("mai") * c(0.7, 0.8, 0.7, 0.6))

> layout(matrix(1:4, ncol = 2))

> mdplot(log(AMLlearn$time), AMLprf, main = "Random Forest", 
+     cex = AMLw/4, ylim = c(-4, 4), xlim = c(0, 7))

> plot(log(AMLlearn$time), AMLprf, cex = AMLw/4, ylim = range(log(AMLlearn$time)), 
+     ylab = "Predicted", xlab = "Observed", main = "Random Forest ..." ... [TRUNCATED] 

> abline(h = Mmod, lty = 2)

> mdplot(log(AMLlearn$time), AMLpb, cex = AMLw/4, main = "Boosting", 
+     ylim = c(-4, 4), xlim = c(0, 7))

> plot(log(AMLlearn$time), AMLpb, cex = AMLw/4, ylim = range(log(AMLlearn$time)), 
+     ylab = "Predicted", xlab = "Observed", main = "Boosting", 
+  .... [TRUNCATED] 

> abline(h = Mmod, lty = 2)

> data("GBSG2", package = "TH.data")

> GBSG2w <- IPCweights(Surv(GBSG2$time, GBSG2$cens))

> GBSG2learn <- cbind(GBSG2[, -which(names(GBSG2) %in% 
+     c("time", "cens"))], ltime = log(GBSG2$time))

> n <- nrow(GBSG2learn)

> LMmod <- lm(ltime ~ ., data = GBSG2learn, weights = GBSG2w)

> LMerisk <- sum((GBSG2learn$ltime - predict(LMmod))^2 * 
+     GBSG2w)/n

> pos <- GBSG2w > 0

> TRmod <- rpart(ltime ~ ., data = GBSG2learn, weights = GBSG2w, 
+     subset = pos)

> TRerisk <- sum((GBSG2learn$ltime[pos] - predict(TRmod))^2 * 
+     GBSG2w[pos])/n

> ctrl <- ctree_control(testtype = "Teststatistic", 
+     teststat = "maximum", mincriterion = qnorm(0.95), minsplit = 5)

> RFmod <- cforest(ltime ~ ., data = GBSG2learn, weights = GBSG2w, 
+     control = ctrl, mtry = 5, ntree = 100, perturb = list(replace = TRUE, 
+     .... [TRUNCATED] 

> L2Bmod <- glmboost(ltime ~ ., data = GBSG2learn, weights = GBSG2w, 
+     control = boost_control(mstop = 250))

> L2BHubermod <- glmboost(ltime ~ ., data = GBSG2learn, 
+     weights = GBSG2w, family = Huber(d = log(2)))

> plot(aic <- AIC(L2Bmod))

> GBSG2Hp <- predict(L2BHubermod, newdata = GBSG2learn)

> L2Berisk <- sum((GBSG2learn$ltime - predict(L2Bmod, 
+     newdata = GBSG2learn))^2 * GBSG2w)/n

> RFerisk <- sum((GBSG2learn$ltime - predict(RFmod, 
+     newdata = GBSG2learn))^2 * GBSG2w)/n

> lim <- c(4, 9)

> mylwd <- 0.5

> par(mai = par("mai") * c(0.7, 0.8, 0.7, 0.6))

> layout(matrix(1:4, ncol = 2))

> Mmod <- sum(GBSG2w * GBSG2learn$ltime)/sum(GBSG2w)

> mdplot(GBSG2learn$ltime, predict(LMmod), cex = GBSG2w/4, 
+     main = "Linear Model", ylim = c(-3, 3), xlim = c(5, 8))

> mdplot(GBSG2learn$ltime[pos], predict(TRmod), cex = GBSG2w/4, 
+     main = "Tree", ylim = c(-3, 3), xlim = c(5, 8))

> mdplot(GBSG2learn$ltime, predict(RFmod, newdata = GBSG2learn), 
+     cex = GBSG2w/4, main = "Random Forest", ylim = c(-3, 3), 
+     xlim = c(5, 8) .... [TRUNCATED] 

> mdplot(GBSG2learn$ltime, predict(L2Bmod, newdata = GBSG2learn), 
+     cex = GBSG2w/4, main = "Boosting", ylim = c(-3, 3), xlim = c(5, 
+         8) .... [TRUNCATED] 

> RFpr <- predict(RFmod, newdata = GBSG2learn)

> L2Bpr <- predict(L2Bmod, newdata = GBSG2learn)

> ylim <- range(c(RFpr[GBSG2w > 0], L2Bpr[GBSG2w > 0]))

> mydf <- 4

> par(mai = par("mai") * c(0.7, 0.8, 0.4, 0.6))

> layout(matrix(1:4, ncol = 2))

> plot(GBSG2learn$pnodes, RFpr, cex = GBSG2w/4, xlim = c(0, 
+     40), lwd = mylwd, xlab = "Nr. positive lymph nodes", ylim = ylim, 
+     ylab = exp .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$pnodes, RFpr, GBSG2w/4, 
+     df = mydf))

> plot(GBSG2learn$age, RFpr, cex = GBSG2w/4, xlab = "Age", 
+     ylab = expression(hat(Y)), ylim = ylim, lwd = mylwd, cex.axis = CEX, 
+     cex.main .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$age, RFpr, GBSG2w/4, 
+     df = mydf))

> plot(GBSG2learn$estrec, RFpr, cex = GBSG2w/4, xlab = "Estrogen receptor", 
+     ylab = expression(hat(Y)), ylim = ylim, lwd = mylwd, cex.axis = CEX .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$estrec, RFpr, GBSG2w/4, 
+     df = mydf))

> indx <- which(GBSG2learn$progrec < 100)

> plot(GBSG2learn$progrec[indx], RFpr[indx], cex = GBSG2w[indx]/4, 
+     xlab = "Progesterone receptor (< 100 fmol / l)", ylab = expression(hat(Y)),  .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$progrec[indx], RFpr[indx], 
+     GBSG2w[indx]/4, df = mydf))

> par(mai = par("mai") * c(0.7, 0.8, 0.4, 0.6))

> layout(matrix(1:4, ncol = 2))

> plot(GBSG2learn$pnodes, L2Bpr, cex = GBSG2w/4, xlim = c(0, 
+     40), ylab = expression(hat(Y)), xlab = "Nr. positive lymph nodes", 
+     ylim = y .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$pnodes, L2Bpr, GBSG2w/4, 
+     df = mydf))

> plot(GBSG2learn$age, L2Bpr, cex = GBSG2w/4, xlab = "Age", 
+     ylab = expression(hat(Y)), ylim = ylim, lwd = mylwd, cex.axis = CEX, 
+     cex.mai .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$age, L2Bpr, GBSG2w/4, 
+     df = mydf))

> plot(GBSG2learn$estrec, L2Bpr, cex = GBSG2w/4, xlab = "Estrogen receptor", 
+     ylab = expression(hat(Y)), ylim = ylim, lwd = mylwd, cex.axis = CE .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$estrec, L2Bpr, GBSG2w/4, 
+     df = mydf))

> indx <- which(GBSG2learn$progrec < 100)

> plot(GBSG2learn$progrec[indx], L2Bpr[indx], cex = GBSG2w[indx]/4, 
+     xlab = "Progesterone receptor (< 100 fmol / l)", ylab = expression(hat(Y)), .... [TRUNCATED] 

> lines(smooth.spline(GBSG2learn$progrec[indx], L2Bpr[indx], 
+     GBSG2w[indx]/4, df = mydf))

> Mmod <- sum(GBSG2w * GBSG2learn$ltime)/sum(GBSG2w)

> par(mai = par("mai") * c(0.7, 0.8, 0.7, 0.6))

> layout(matrix(1:4, ncol = 2))

> yl <- range(c(GBSG2Hp[GBSG2w > 0], L2Bpr[GBSG2w > 
+     0]))

> mdplot(GBSG2learn$ltime, GBSG2Hp, main = "Huber Loss", 
+     cex = GBSG2w/4, ylim = c(-3, 3), xlim = c(5, 8))

> plot(GBSG2learn$ltime, GBSG2Hp, cex = GBSG2w/4, xlim = range(GBSG2learn$ltime[GBSG2w > 
+     0]), ylim = yl, ylab = "Predicted", xlab = "Observed", .... [TRUNCATED] 

> mdplot(GBSG2learn$ltime, L2Bpr, cex = GBSG2w/4, main = "Quadratic Loss", 
+     ylim = c(-3, 3), xlim = c(5, 8))

> plot(GBSG2learn$ltime, L2Bpr, cex = GBSG2w/4, xlim = range(GBSG2learn$ltime[GBSG2w > 
+     0]), ylim = yl, ylab = "Predicted", xlab = "Observed", m .... [TRUNCATED] 

 *** Run successfully completed ***
> proc.time()
   user  system elapsed 
  9.909   0.093  10.000 
